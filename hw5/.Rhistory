.by = c(word)) |>
bind_tf_idf(word,
season,
term_frequency) |>
arrange(desc(tf_idf))
tokenized_data <- theoffice %>%
unnest_tokens(word, text)
# Calculate term frequency (TF)
tf <- tokenized_data %>%
count(season, word) %>%
group_by(season) %>%
mutate(tf = n / sum(n))
# Calculate inverse document frequency (IDF)
idf <- theoffice %>%
unnest_tokens(word, text) |>
count(word, season) %>%
ungroup() %>%
bind_tf_idf(word, season, n) %>%
select(season, word, tf_idf)
# Find the word with the highest TF-IDF score for each season
top_words <- idf %>%
group_by(season) %>%
slice_max(order_by = tf_idf, n = 1)
# Print the word with the highest TF-IDF score for each season
print(top_words)
tfidf <- theoffice |>
unnest_tokens(word, text) |>
count(word, season) |>
ungroup() |>
bind_tf_idf(word, season, n) |>
select(season, word, tf_idf)
top_words <- tfidf |>
group_by(season) |>
slice_max(order_by = tf_idf, n = 1)
top_words
tfidf <- theoffice |>
unnest_tokens(word, text) |>
count(word, season) |>
ungroup() |>
bind_tf_idf(word, season, n) |>
select(season, word, tf_idf)
top_words <- tfidf |>
group_by(season) |>
slice_max(order_by = tf_idf, n = 2)
top_words
tfidf <- theoffice |>
unnest_tokens(word, text) |>
count(word, season) |>
ungroup() |>
bind_tf_idf(word, season, n) |>
select(season, word, tf_idf)
top_words <- tfidf |>
group_by(season) |>
slice_max(order_by = tf_idf, n = 1)
top_words
library(tm)
"will"
install.packages("tm")
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, character)
# Create a document-term matrix
dtm <- office_tokens |>
count(episode, word) |>
cast_dtm(episode, word, n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, character)
# Create a document-term matrix
dtm <- office_tokens |>
count(episode, word) |>
cast_dtm(episode, word, n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
# Create a document-term matrix
dtm <- office_tokens |>
count(episode, word) |>
cast_dtm(episode, word, n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(episode, character)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(character, episode)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(epsiode, character) |>
cast_dtm(document = episode,
term = character,
value = term_frequency)
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(epsiode, character) |>
cast_dtm(document = episode,
term = character,
value = n)
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
mutate(char_freq = count(epsiode, character)) |>
cast_dtm(document = episode,
term = character,
value = char_freq)
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
mutate(char_freq = count(epsiode, character))
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(epsiode, character) |>
cast_dtm(document = episode,
term = character,
value = n)
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
mutate(char_freq = count(episode, character)) |>
cast_dtm(document = episode,
term = character,
value = char_freq)
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(epsiode, character) |>
cast_dtm(document = episode,
term = character,
value = n)
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(episode, character) |>
cast_dtm(document = episode,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(season, episode, character) |>
cast_dtm(document = episode,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(topicmodels)
install.packages("topicmodels")
library(topicmodels)
lda <- LDA(dtm, k = 4)
lda
library(topicmodels)
lda <- LDA(dtm, k = 4)
lda
lda_topics <- lda |>
tidy(matrix = "beta")
lda_topics |>
head()
lda_topics <- lda |>
tidy(matrix = "beta")
lda_topics
lda_topics <- lda |>
tidy(matrix = "beta")
lda_topics |>
slice_max(beta,
n = 10)
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
term,
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
reorder(term, n),
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
reorder(term, beta),
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
reorder(term, -beta),
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
reorder(term, beta),
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
office_names <- theoffice |>
unnest_tokens(word,
text) |>
filter(word %in% popular_names) |>
count(word) |>
arrange(desc(n)) |>
mutate(thereornot = word %in% chars) |>
head(40)
office_names |>
ggplot(aes(x = n, y = reorder(word, n), fill = thereornot)) +
geom_bar(stat = "identity") +
labs(x = "Mentions in Show",
y = "Character Name") +
geom_col(show.legend = FALSE)
office_names <- theoffice |>
unnest_tokens(word,
text) |>
filter(word %in% popular_names) |>
count(word) |>
arrange(desc(n)) |>
mutate(thereornot = word %in% chars) |>
head(40)
office_names |>
ggplot(aes(x = n, y = reorder(word, n), fill = thereornot)) +
geom_bar(stat = "identity") +
labs(x = "Mentions in Show",
y = "Character Name") +
geom_fill(show.legend = FALSE)
office_names <- theoffice |>
unnest_tokens(word,
text) |>
filter(word %in% popular_names) |>
count(word) |>
arrange(desc(n)) |>
mutate(thereornot = word %in% chars) |>
head(40)
office_names |>
ggplot(aes(x = n, y = reorder(word, n), fill = thereornot)) +
geom_bar(stat = "identity") +
labs(x = "Mentions in Show",
y = "Character Name") +
geom_bar(show.legend = FALSE)
office_names <- theoffice |>
unnest_tokens(word,
text) |>
filter(word %in% popular_names) |>
count(word) |>
arrange(desc(n)) |>
mutate(thereornot = word %in% chars) |>
head(40)
office_names |>
ggplot(aes(x = n, y = reorder(word, n), fill = thereornot)) +
geom_bar(stat = "identity") +
labs(x = "Mentions in Show",
y = "Character Name")
office_names <- theoffice |>
unnest_tokens(word,
text) |>
filter(word %in% popular_names) |>
count(word) |>
arrange(desc(n)) |>
mutate(thereornot = word %in% chars) |>
head(40)
office_names |>
ggplot(aes(x = n, y = reorder(word, n), fill = thereornot)) +
geom_bar(stat = "identity") +
labs(x = "Mentions in Show",
y = "Character Name") +
theme(legend.position = "none")
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
term,
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
ggplot(lda_topics, aes(x = episode, y = topic_proportion, fill = factor(topic))) +
geom_bar(stat = "identity") +
labs(title = "Distribution of Topics Across Episodes and Seasons",
x = "Episode",
y = "Topic Proportion") +
facet_wrap(~ season, scales = "free_x", ncol = 1) +
theme(legend.position = "none")  # Hide legend
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(season, episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(data, writer, sep = " & ")
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = " & ")
dtm <- office_tokens |>
count(episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = " & ")
dtm <- office_tokens |>
count(season, episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(topicmodels)
lda <- LDA(dtm, k = 4)
lda
lda_topics <- lda |>
tidy(matrix = "beta")
top_terms <- lda_topics |>
group_by(topic) |>
slice_max(beta,
n = 10) |>
mutate(topic = factor(topic))
top_terms |>
ggplot(aes(beta,
term,
fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic,
scales = "free_y",
ncol = 4)
ggplot(lda_topics, aes(x = episode, y = topic_proportion, fill = factor(topic))) +
geom_bar(stat = "identity") +
labs(title = "Distribution of Topics Across Episodes and Seasons",
x = "Episode",
y = "Topic Proportion") +
facet_wrap(~ season, scales = "free_x", ncol = 1) +
theme(legend.position = "none")  # Hide legend
lda_memberships <- lda |>
tidy(matrix = "gamma")
lda_memberships |>
filter(document %in% c(1:9)) |>
ggplot(aes(y = factor(topic),
x = gamma,
fill = factor(document))) +
geom_col() +
facet_wrap(~document) +
theme(legend.position = "none") +
labs(x = "Membership Share",
y = "Topic") +
xlim(c(0,1))
lda_memberships <- lda |>
tidy(matrix = "gamma")
lda_memberships |>
filter(document %in% c(1:9)) |>
ggplot(aes(y = factor(topic),
x = gamma,
fill = factor(document))) +
geom_col() +
facet_wrap(~ season) +
theme(legend.position = "none") +
labs(x = "Membership Share",
y = "Topic") +
xlim(c(0,1))
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = " & ")
dtm <- office_tokens |>
count(season, episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
office_tokens
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = " & ")
dtm <- office_tokens |>
count(season, episode_name, character) |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = " & ")
dtm <- office_tokens |>
count(season, episode_name, character)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(season, episode_name, character)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = "\\s*[&/]+\\s*| and ")
dtm <- office_tokens |>
count(season, episode_name, character)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text) |>
separate_rows(character, sep = "\\s*[&/]+\\s*| and ")
dtm <- office_tokens |>
count(season, episode_name, character)  |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
library(tm)
office_tokens <- theoffice |>
unnest_tokens(word, text)
dtm <- office_tokens |>
count(season, episode_name, character)  |>
cast_dtm(document = episode_name,
term = character,
value = n)
dtm
